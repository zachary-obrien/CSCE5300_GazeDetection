{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import cv2\n",
    "import __main__\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import image \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D, Dense, Dropout, Flatten \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 606.39it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 571.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Value Counts\n",
      "1    50\n",
      "2    50\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Test Value Counts\n",
      "1    6\n",
      "2    6\n",
      "dtype: int64\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "X Train Shape\n",
      "(100, 150, 150, 3)\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "X Test Shape\n",
      "(12, 150, 150, 3)\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_image_value(path, dim): \n",
    "    '''This function will read an image and convert/resize'''\n",
    "    img = image.load_img(path, target_size = dim)\n",
    "    img = image.img_to_array(img)\n",
    "    return img/255\n",
    "\n",
    "def get_img_array(img_paths, dim): \n",
    "    '''This fucntion takes a list of image paths and returns np arrays.'''\n",
    "    final_array = []\n",
    "    from tqdm import tqdm\n",
    "    for path in tqdm(img_paths):\n",
    "        img = get_image_value(path, dim)\n",
    "        final_array.append(img)\n",
    "    final_array = np.array(final_array)  \n",
    "    return final_array\n",
    "\n",
    "def get_tts():\n",
    "    '''This function will create a train test split'''  \n",
    "   \n",
    "    DIM =  (150,150) \n",
    "    np.random.seed(10)        \n",
    "    \n",
    "    faces_paths = [f'./Extracted_Data/00002/appleFace/{i}' for i in os.listdir(f'./Extracted_Data/00002/appleFace')]  \n",
    "    faces_labels = [1 for i in range(len(faces_paths))]\n",
    "    \n",
    "    left_paths = [f'./Extracted_Data/00002/appleLeftEye/{i}' for i in os.listdir('./Extracted_Data/00002/appleLeftEye')] \n",
    "    left_labels = [2 for i in range(len(left_paths))]    \n",
    "    \n",
    "    right_paths = [f'./Extracted_Data/00002/appleRightEye/{i}' for i in os.listdir('./Extracted_Data/00002/appleRightEye')]\n",
    "    \n",
    "    np.random.shuffle(right_paths)\n",
    "    right_paths = right_paths[:len(faces_paths)- 500]\n",
    "    right_labels = [0 for i in range(len(right_paths))]\n",
    "\n",
    "    np.random.shuffle(faces_paths)\n",
    "    faces_paths = faces_paths[:len(left_paths)+150]\n",
    "    right_paths = right_paths[:len(left_paths)+150]\n",
    "\n",
    "    faces_labels = [1 for i in range(len(faces_paths))]\n",
    "    left_labels = [2 for i in range(len(left_paths))]\n",
    "    right_labels = [0 for i in range(len(right_paths))]\n",
    "    paths = faces_paths + left_paths + right_paths\n",
    "    labels = faces_labels + left_labels + right_labels\n",
    "    x_train, x_test, y_train, y_test = train_test_split(paths, labels, stratify = labels, train_size = .90, random_state = 10)\n",
    "\n",
    "    new_x_train = get_img_array(x_train, DIM)\n",
    "    new_x_test = get_img_array(x_test, DIM)\n",
    "    \n",
    "    print('Train Value Counts')\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('Test Value Counts')\n",
    "    print(pd.Series(y_test).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('X Train Shape')\n",
    "    print(new_x_train.shape)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('X Test Shape')\n",
    "    print(new_x_test.shape)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    y_test = to_categorical(y_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    tts = (new_x_train, new_x_test, y_train, y_test)\n",
    "    \n",
    "    return tts\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_tts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D, Dense, Dropout, Flatten \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "\n",
    "def get_conv_model(dim = (150,150, 3)):\n",
    "    '''This function will create and compile a CNN given the input dimension'''\n",
    "    inp_shape = dim\n",
    "    act = 'relu'\n",
    "    drop = .25\n",
    "    kernal_reg = regularizers.l1(.001)\n",
    "    optimizer = Adam(lr = .0001)    \n",
    "    model = Sequential() \n",
    "    model.add(Conv2D(64, kernel_size=(3,3),activation=act, input_shape = inp_shape, \n",
    "                     kernel_regularizer = kernal_reg,\n",
    "                     kernel_initializer = 'he_uniform',  padding = 'same', name = 'Input_Layer'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (3,3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3))) \n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))  \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(3, activation='softmax', name = 'Output_Layer'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin_PC_W10\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 0s - loss: 11.8139 - accuracy: 0.6300\n",
      "Epoch 1: val_loss improved from inf to 11.18729, saving model to ModelWeights.h5\n",
      "50/50 [==============================] - 4s 64ms/step - loss: 11.8139 - accuracy: 0.6300 - val_loss: 11.1873 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 10.8089 - accuracy: 0.8500\n",
      "Epoch 2: val_loss improved from 11.18729 to 10.23607, saving model to ModelWeights.h5\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 10.8089 - accuracy: 0.8500 - val_loss: 10.2361 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "49/50 [============================>.] - ETA: 0s - loss: 9.8808 - accuracy: 0.9694\n",
      "Epoch 3: val_loss improved from 10.23607 to 9.43534, saving model to ModelWeights.h5\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 9.8719 - accuracy: 0.9700 - val_loss: 9.4353 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 9.2082 - accuracy: 0.9500\n",
      "Epoch 4: val_loss improved from 9.43534 to 8.81642, saving model to ModelWeights.h5\n",
      "50/50 [==============================] - 3s 67ms/step - loss: 9.2082 - accuracy: 0.9500 - val_loss: 8.8164 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 8.5091 - accuracy: 1.0000\n",
      "Epoch 5: val_loss improved from 8.81642 to 8.18203, saving model to ModelWeights.h5\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 8.5091 - accuracy: 1.0000 - val_loss: 8.1820 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 7.9349 - accuracy: 0.9800\n",
      "Epoch 6: val_loss improved from 8.18203 to 7.60702, saving model to ModelWeights.h5\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 7.9349 - accuracy: 0.9800 - val_loss: 7.6070 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 7.4243 - accuracy: 0.9700\n",
      "Epoch 7: val_loss improved from 7.60702 to 7.09622, saving model to ModelWeights.h5\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 7.4243 - accuracy: 0.9700 - val_loss: 7.0962 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "49/50 [============================>.] - ETA: 0s - loss: 6.9140 - accuracy: 0.9694\n",
      "Epoch 8: val_loss improved from 7.09622 to 6.58418, saving model to ModelWeights.h5\n",
      "50/50 [==============================] - 3s 60ms/step - loss: 6.9096 - accuracy: 0.9700 - val_loss: 6.5842 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 6.3604 - accuracy: 1.0000\n",
      "Epoch 9: val_loss improved from 6.58418 to 6.09817, saving model to ModelWeights.h5\n",
      "50/50 [==============================] - 3s 61ms/step - loss: 6.3604 - accuracy: 1.0000 - val_loss: 6.0982 - val_accuracy: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 5.9307 - accuracy: 0.9800\n",
      "Epoch 10: val_loss improved from 6.09817 to 5.67066, saving model to ModelWeights.h5\n",
      "50/50 [==============================] - 3s 59ms/step - loss: 5.9307 - accuracy: 0.9800 - val_loss: 5.6707 - val_accuracy: 1.0000 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#prevents overfitting and saves models every time the validation loss improves\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint('ModelWeights.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n",
    "epochs = 10\n",
    "batch_size = 2\n",
    "model = get_conv_model()\n",
    "model_history = model.fit(x_train, y_train, batch_size = batch_size,\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Extracted_Data/00000_Tests/aTWO.JPG\t\tPrediction: Face\t100% Confident\n",
      "Creating Bounding Boxes for ./Extracted_Data/00000_Tests/aTWO.JPG\n",
      "Found 3 faces!\n",
      "Found 3 faces!\n",
      "Found 3 faces!\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "./Extracted_Data/00000_Tests/Face_00000.jpg\t\tPrediction: Face\t100% Confident\n",
      "Creating Bounding Boxes for ./Extracted_Data/00000_Tests/Face_00000.jpg\n",
      "Found 1 faces!\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "./Extracted_Data/00000_Tests/X.jpg\t\tPrediction: Face\t99% Confident\n",
      "Creating Bounding Boxes for ./Extracted_Data/00000_Tests/X.jpg\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "cascPath = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "def non_max_suppression(boxes, overlapThresh= .5):\n",
    "    \n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1, y1, x2, y2 = boxes[:,0], boxes[:,1], boxes[:,2], boxes[:,3]    \n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1, yy1, xx2, yy2 = np.maximum(x1[i], x1[idxs[:last]]), np.maximum(y1[i], y1[idxs[:last]]), np.minimum(x2[i], x2[idxs[:last]]), np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w, h = np.maximum(0, xx2 - xx1 + 1), np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return pick\n",
    "\n",
    "def get_img_prediction_bounding_box(path, model, dim):\n",
    "    '''This function will create a bounding box over what it believes is a \n",
    "    Face given the image path, dimensions, and model used to detect the Face.  \n",
    "    Dimensions can be found within the Var.py file.  This function is still \n",
    "    being used as I need to apply non-max suppresion to create only one bounding box'''\n",
    "    img = get_image_value(path, dim)   \n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], 3)\n",
    "    pred = model.predict(img)[0]\n",
    "    category_dict = {0: 'LeftEye', 1: 'Face', 2: 'RightEye'}\n",
    "    cat_index = np.argmax(pred)\n",
    "    cat = category_dict[cat_index]\n",
    "    print(f'{path}\\t\\tPrediction: {cat}\\t{int(pred.max()*100)}% Confident')\n",
    "\n",
    "    #speed up cv2\n",
    "    cv2.setUseOptimized(True)\n",
    "    cv2.setNumThreads(10) #change depending on your computer\n",
    "    img = cv2.imread(path)\n",
    "    clone = img.copy()\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "\n",
    "    rects = ss.process() \n",
    "    windows = []\n",
    "    locations = []\n",
    "    \n",
    "    print(f'Creating Bounding Boxes for {path}')\n",
    "    for x, y, w,h in rects[:1001]: \n",
    "        startx, starty, endx, endy = x, y, x+w, y+h \n",
    "        roi = img[starty:endy, startx:endx]\n",
    "        roi = cv2.resize(roi, dsize =dim, interpolation = cv2.INTER_CUBIC)\n",
    "        windows.append(roi)\n",
    "        locations.append((startx, starty, endx, endy))\n",
    "    \n",
    "    gray = cv2.cvtColor(clone, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "    \n",
    "    windows = np.array(windows)\n",
    "    windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 3)\n",
    "    windows = np.array(windows)\n",
    "    locations = np.array(locations)\n",
    "    predictions = model.predict(windows)\n",
    "    nms = non_max_suppression(locations)\n",
    "    bounding_cnt = 0\n",
    "        \n",
    "    if len(faces) > 0:\n",
    "    \n",
    "        # Draw a rectangle around the faces\n",
    "        for (x1, y1, w, h) in faces:\n",
    "            print(\"Found {0} faces!\".format(len(faces)))\n",
    "            startx, starty, endx, endy = (x1, y1, w, h)\n",
    "            cv2.rectangle(clone, (x1, y1), (x1+w, y1+h), (0, 255, 0), 2)\n",
    "            text = f'{category_dict[np.argmax(predictions[cat_index])]}: {int(predictions[cat_index].max()*100)}%'\n",
    "            cv2.putText(clone, text, (startx, starty+15), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,255,0),2)\n",
    "            cv2.imshow(\"Faces found\", clone)\n",
    "            #cv2.imshow(f'Test', np.hstack([clone, clone2]))\n",
    "            #cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "        \n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        cv2.imshow(\"No Faces found\", clone)\n",
    "           \n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    cv2.waitKey(0)\n",
    "    ss.clear()\n",
    "    return predictions\n",
    "\n",
    "#NORMAL MODEL\n",
    "dim = (150, 150, 3)    \n",
    "normal_model = get_conv_model(dim)\n",
    "normal_model.load_weights('ModelWeights.h5') #path to the model weights\n",
    "test_folder = './Extracted_Data/00000_Tests' #folder where you will put your images to test\n",
    "predictions = []\n",
    "for idx, i in enumerate([i for i in os.listdir(test_folder) if i != 'ipynb_checkpoints']):\n",
    "    img_path = f'{test_folder}/{i}'\n",
    "    pred = get_img_prediction_bounding_box(img_path, normal_model, dim = (150,150))\n",
    "    predictions.append(pred)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1da653b9d4e8419f9e4e7f34517b2d166406bf3bd28c5de51c8f75fec185e0c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
